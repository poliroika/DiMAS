"""
ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ñ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð³Ð¸Ð¸ "Ð·Ð²ÐµÐ·Ð´Ð¾Ñ‡ÐºÐ°" Ñ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ð¼Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸.

Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÑ‚:
- ÐŸÐ°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² (5 ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð¾Ð²)
- ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸ÑŽ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¾Ð´Ð½Ð¸Ð¼ Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð¼ (Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚)
- Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð² JSON
- Ð¢Ð¾Ð¿Ð¾Ð»Ð¾Ð³Ð¸ÑŽ star: Ð²ÑÐµ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ñ‹ â†’ Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚

Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°:
    ÐžÑ€Ñ‚Ð¾Ð¿ÐµÐ´ â”€â”€â”€â”€â”€â”
    ÐžÐºÑƒÐ»Ð¸ÑÑ‚ â”€â”€â”€â”€â”€â”¤
    ÐšÐ°Ñ€Ð´Ð¸Ð¾Ð»Ð¾Ð³ â”€â”€â”€â”¼â”€â”€â†’ Ð¢ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚ (Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð´Ð¸Ð°Ð³Ð½Ð¾Ð·)
    ÐÐµÐ²Ñ€Ð¾Ð»Ð¾Ð³ â”€â”€â”€â”€â”¤
    Ð”ÐµÑ€Ð¼Ð°Ñ‚Ð¾Ð»Ð¾Ð³ â”€â”€â”˜
"""

import json
import sys
import time
from datetime import datetime
from pathlib import Path

from rustworkx_framework.builder import GraphBuilder
from rustworkx_framework.core.graph import RoleGraph
from rustworkx_framework.execution import LLMCallerFactory, MACPRunner, RunnerConfig

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ Ð´Ð»Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¾Ð² Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²
AGENT_IO_LOG = {}


def create_logging_caller_factory():
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ LLM caller factory Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð°/Ð²Ñ‹Ñ…Ð¾Ð´Ð°."""
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²ÑƒÑŽ Ñ„Ð°Ð±Ñ€Ð¸ÐºÑƒ
    base_factory = LLMCallerFactory.create_openai_factory()

    class LoggingFactory:
        """ÐžÐ±ÐµÑ€Ñ‚ÐºÐ° Ñ„Ð°Ð±Ñ€Ð¸ÐºÐ¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð»Ð¾Ð³Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ‹ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹."""

        def __init__(self, base_factory):
            self.base_factory = base_factory
            # ÐŸÑ€Ð¾Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ Ð²ÑÐµ Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ‚Ñ‹ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð¹ Ñ„Ð°Ð±Ñ€Ð¸ÐºÐ¸
            self.default_caller = base_factory.default_caller
            self.default_async_caller = base_factory.default_async_caller
            self.default_config = base_factory.default_config
            self.caller_builder = base_factory.caller_builder
            self.async_caller_builder = base_factory.async_caller_builder

        def get_caller(self, config=None, agent_id=None):
            """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ caller Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼."""
            base_caller = self.base_factory.get_caller(config, agent_id)

            if base_caller is None:
                return None

            def logging_caller(prompt: str) -> str:
                """ÐžÐ±ÐµÑ€Ñ‚ÐºÐ° caller, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð»Ð¾Ð³Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚."""
                # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
                if agent_id:
                    if agent_id not in AGENT_IO_LOG:
                        AGENT_IO_LOG[agent_id] = {}
                    AGENT_IO_LOG[agent_id]["input_prompt"] = prompt
                    AGENT_IO_LOG[agent_id]["input_length"] = len(prompt)

                # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¹ LLM
                response = base_caller(prompt)

                # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚
                if agent_id:
                    AGENT_IO_LOG[agent_id]["output_response"] = response
                    AGENT_IO_LOG[agent_id]["output_length"] = len(response)

                return response

            return logging_caller

        def get_async_caller(self, config=None, agent_id=None):
            """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ async caller Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼."""
            return self.base_factory.get_async_caller(config, agent_id)

        def get_streaming_caller(self, config=None, agent_id=None):
            """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ streaming caller Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼."""
            return self.base_factory.get_streaming_caller(config, agent_id)

        def get_async_streaming_caller(self, config=None, agent_id=None):
            """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ async streaming caller Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼."""
            return self.base_factory.get_async_streaming_caller(config, agent_id)

    return LoggingFactory(base_factory)


# ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ LLM (Ð¼Ð¾Ð¶Ð½Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð²)
DEFAULT_LLM_CONFIG = {
    "api_key": "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",
    "base_url": "https://advisory-locked-summaries-steady.trycloudflare.com/v1",
    "model_name": "./models/Qwen3-Next-80B-A3B-Instruct",
}

# Ð¡Ð»ÑƒÑ‡Ð°Ð¹ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð° Ð´Ð»Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ¸
PATIENT_CASE = """
ÐŸÐ°Ñ†Ð¸ÐµÐ½Ñ‚: ÐœÑƒÐ¶Ñ‡Ð¸Ð½Ð°, 45 Ð»ÐµÑ‚

Ð–Ð°Ð»Ð¾Ð±Ñ‹:
- Ð‘Ð¾Ð»ÑŒ Ð² Ð¿Ñ€Ð°Ð²Ð¾Ð¼ ÐºÐ¾Ð»ÐµÐ½Ðµ Ð¿Ñ€Ð¸ Ñ…Ð¾Ð´ÑŒÐ±Ðµ (3 Ð½ÐµÐ´ÐµÐ»Ð¸)
- ÐŸÐµÑ€Ð¸Ð¾Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð³Ð¾Ð»Ð¾Ð²Ð½Ñ‹Ðµ Ð±Ð¾Ð»Ð¸
- Ð£Ñ…ÑƒÐ´ÑˆÐµÐ½Ð¸Ðµ Ð·Ñ€ÐµÐ½Ð¸Ñ (Ñ€Ð°Ð·Ð¼Ñ‹Ñ‚Ð¾ÑÑ‚ÑŒ Ð½Ð° Ð´Ð°Ð»ÑŒÐ½Ð¸Ñ… Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸ÑÑ…)
- ÐŸÐ¾Ð²Ñ‹ÑˆÐµÐ½Ð½Ð¾Ðµ Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ (150/95)
- Ð¡ÑƒÑ…Ð¾ÑÑ‚ÑŒ ÐºÐ¾Ð¶Ð¸ Ð½Ð° Ñ€ÑƒÐºÐ°Ñ… Ð¸ Ð»Ð¾ÐºÑ‚ÑÑ…
- ÐžÐ±Ñ‰Ð°Ñ ÑƒÑÑ‚Ð°Ð»Ð¾ÑÑ‚ÑŒ

ÐÐ½Ð°Ð¼Ð½ÐµÐ·:
- Ð Ð°Ð±Ð¾Ñ‚Ð° Ð² Ð¾Ñ„Ð¸ÑÐµ (ÑÐ¸Ð´ÑÑ‡Ð°Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°)
- Ð—Ð°Ð½Ð¸Ð¼Ð°ÐµÑ‚ÑÑ Ð±ÐµÐ³Ð¾Ð¼ (3 Ñ€Ð°Ð·Ð° Ð² Ð½ÐµÐ´ÐµÐ»ÑŽ)
- Ð¡Ñ‚Ñ€ÐµÑÑ Ð½Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ðµ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 2 Ð¼ÐµÑÑÑ†Ð°
- ÐÐ°ÑÐ»ÐµÐ´ÑÑ‚Ð²ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: Ñƒ Ð¾Ñ‚Ñ†Ð° Ð³Ð¸Ð¿ÐµÑ€Ñ‚Ð¾Ð½Ð¸Ñ
"""


def create_medical_graph() -> RoleGraph:
    """Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð³Ñ€Ð°Ñ„ Ñ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ð¼Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ð² Ñ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð³Ð¸Ð¸ Ð·Ð²ÐµÐ·Ð´Ð¾Ñ‡ÐºÐ°."""
    builder = GraphBuilder()

    # 1. ÐžÐ Ð¢ÐžÐŸÐ•Ð” - ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð° Ð¾Ð¿Ð¾Ñ€Ð½Ð¾-Ð´Ð²Ð¸Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð°Ð¿Ð¿Ð°Ñ€Ð°Ñ‚Ðµ
    builder.add_agent(
        "orthopedist",
        display_name="ÐžÑ€Ñ‚Ð¾Ð¿ÐµÐ´",
        persona="Ð’Ñ‹ Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹ Ð²Ñ€Ð°Ñ‡-Ð¾Ñ€Ñ‚Ð¾Ð¿ÐµÐ´ Ñ 15-Ð»ÐµÑ‚Ð½Ð¸Ð¼ ÑÑ‚Ð°Ð¶ÐµÐ¼",
        description=(
            "ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¾Ð¿Ð¾Ñ€Ð½Ð¾-Ð´Ð²Ð¸Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð¿Ð¿Ð°Ñ€Ð°Ñ‚Ð° Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°. "
            "ÐžÐ±Ñ€Ð°Ñ‚Ð¸Ñ‚Ðµ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð½Ð° Ð±Ð¾Ð»Ð¸ Ð² ÑÑƒÑÑ‚Ð°Ð²Ð°Ñ…, Ð¼Ñ‹ÑˆÑ†Ð°Ñ…, Ð¿Ð¾ÑÐ»ÐµÐ´ÑÑ‚Ð²Ð¸Ñ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸. "
            "ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ (3-5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹) Ñ Ð²Ð°ÑˆÐ¸Ð¼Ð¸ Ð½Ð°Ð±Ð»ÑŽÐ´ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸."
        ),
        llm_backbone=DEFAULT_LLM_CONFIG["model_name"],
        base_url=DEFAULT_LLM_CONFIG["base_url"],
        api_key=DEFAULT_LLM_CONFIG["api_key"],
        temperature=0.3,
        max_tokens=500,
    )

    # 2. ÐžÐšÐ£Ð›Ð˜Ð¡Ð¢ (Ð¾Ñ„Ñ‚Ð°Ð»ÑŒÐ¼Ð¾Ð»Ð¾Ð³) - ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð° Ð·Ñ€ÐµÐ½Ð¸Ð¸
    builder.add_agent(
        "ophthalmologist",
        display_name="ÐžÑ„Ñ‚Ð°Ð»ÑŒÐ¼Ð¾Ð»Ð¾Ð³",
        persona="Ð’Ñ‹ ÐºÐ²Ð°Ð»Ð¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð²Ñ€Ð°Ñ‡-Ð¾Ñ„Ñ‚Ð°Ð»ÑŒÐ¼Ð¾Ð»Ð¾Ð³",
        description=(
            "ÐžÑ†ÐµÐ½Ð¸Ñ‚Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð·Ñ€ÐµÐ½Ð¸Ñ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð° Ð¸ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ Ð³Ð»Ð°Ð·Ð°Ð¼Ð¸. "
            "ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÑÐ¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ñ‹, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾ Ð·Ñ€ÐµÐ½Ð¸ÐµÐ¼. "
            "ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ (3-5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹) Ñ Ð²Ð°ÑˆÐ¸Ð¼Ð¸ Ð½Ð°Ð±Ð»ÑŽÐ´ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸."
        ),
        llm_backbone=DEFAULT_LLM_CONFIG["model_name"],
        base_url=DEFAULT_LLM_CONFIG["base_url"],
        api_key=DEFAULT_LLM_CONFIG["api_key"],
        temperature=0.3,
        max_tokens=500,
    )

    # 3. ÐšÐÐ Ð”Ð˜ÐžÐ›ÐžÐ“ - ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð° ÑÐµÑ€Ð´ÐµÑ‡Ð½Ð¾-ÑÐ¾ÑÑƒÐ´Ð¸ÑÑ‚Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ
    builder.add_agent(
        "cardiologist",
        display_name="ÐšÐ°Ñ€Ð´Ð¸Ð¾Ð»Ð¾Ð³",
        persona="Ð’Ñ‹ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚ Ð¿Ð¾ ÑÐµÑ€Ð´ÐµÑ‡Ð½Ð¾-ÑÐ¾ÑÑƒÐ´Ð¸ÑÑ‚Ñ‹Ð¼ Ð·Ð°Ð±Ð¾Ð»ÐµÐ²Ð°Ð½Ð¸ÑÐ¼",
        description=(
            "ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ ÑÐµÑ€Ð´ÐµÑ‡Ð½Ð¾-ÑÐ¾ÑÑƒÐ´Ð¸ÑÑ‚Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°. "
            "ÐžÐ±Ñ€Ð°Ñ‚Ð¸Ñ‚Ðµ Ð¾ÑÐ¾Ð±Ð¾Ðµ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð½Ð° Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ, Ð½Ð°ÑÐ»ÐµÐ´ÑÑ‚Ð²ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ, Ñ„Ð°ÐºÑ‚Ð¾Ñ€Ñ‹ Ñ€Ð¸ÑÐºÐ°. "
            "ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ (3-5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹) Ñ Ð²Ð°ÑˆÐ¸Ð¼Ð¸ Ð½Ð°Ð±Ð»ÑŽÐ´ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸."
        ),
        llm_backbone=DEFAULT_LLM_CONFIG["model_name"],
        base_url=DEFAULT_LLM_CONFIG["base_url"],
        api_key=DEFAULT_LLM_CONFIG["api_key"],
        temperature=0.3,
        max_tokens=500,
    )

    # 4. ÐÐ•Ð’Ð ÐžÐ›ÐžÐ“ - ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð° Ð½ÐµÑ€Ð²Ð½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ
    builder.add_agent(
        "neurologist",
        display_name="ÐÐµÐ²Ñ€Ð¾Ð»Ð¾Ð³",
        persona="Ð’Ñ‹ Ð²Ñ€Ð°Ñ‡-Ð½ÐµÐ²Ñ€Ð¾Ð»Ð¾Ð³, ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚ Ð¿Ð¾ Ð·Ð°Ð±Ð¾Ð»ÐµÐ²Ð°Ð½Ð¸ÑÐ¼ Ð½ÐµÑ€Ð²Ð½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹",
        description=(
            "ÐžÑ†ÐµÐ½Ð¸Ñ‚Ðµ Ð½ÐµÐ²Ñ€Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ñ‹ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°. "
            "ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð³Ð¾Ð»Ð¾Ð²Ð½Ñ‹Ðµ Ð±Ð¾Ð»Ð¸, ÑÐ²ÑÐ·ÑŒ ÑÐ¾ ÑÑ‚Ñ€ÐµÑÑÐ¾Ð¼, Ð¾Ð±Ñ‰ÐµÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð½ÐµÑ€Ð²Ð½Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹. "
            "ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ (3-5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹) Ñ Ð²Ð°ÑˆÐ¸Ð¼Ð¸ Ð½Ð°Ð±Ð»ÑŽÐ´ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸."
        ),
        llm_backbone=DEFAULT_LLM_CONFIG["model_name"],
        base_url=DEFAULT_LLM_CONFIG["base_url"],
        api_key=DEFAULT_LLM_CONFIG["api_key"],
        temperature=0.3,
        max_tokens=500,
    )

    # 5. Ð”Ð•Ð ÐœÐÐ¢ÐžÐ›ÐžÐ“ - ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð½Ð° ÐºÐ¾Ð¶Ðµ
    builder.add_agent(
        "dermatologist",
        display_name="Ð”ÐµÑ€Ð¼Ð°Ñ‚Ð¾Ð»Ð¾Ð³",
        persona="Ð’Ñ‹ Ð²Ñ€Ð°Ñ‡-Ð´ÐµÑ€Ð¼Ð°Ñ‚Ð¾Ð»Ð¾Ð³ Ñ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¸Ð·Ð¾Ð¹ Ð² Ð´ÐµÑ€Ð¼Ð°Ñ‚Ð¾Ð»Ð¾Ð³Ð¸Ð¸",
        description=(
            "ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ ÐºÐ¾Ð¶Ð¸ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°. "
            "ÐžÐ±Ñ€Ð°Ñ‚Ð¸Ñ‚Ðµ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð½Ð° ÑÐ¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ñ‹ ÑÑƒÑ…Ð¾ÑÑ‚Ð¸, Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñ‹ Ð¸ ÑÐ²ÑÐ·ÑŒ Ñ Ð¾Ð±Ñ‰Ð¸Ð¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÐµÐ¼ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ. "
            "ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ (3-5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹) Ñ Ð²Ð°ÑˆÐ¸Ð¼Ð¸ Ð½Ð°Ð±Ð»ÑŽÐ´ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸."
        ),
        llm_backbone=DEFAULT_LLM_CONFIG["model_name"],
        base_url=DEFAULT_LLM_CONFIG["base_url"],
        api_key=DEFAULT_LLM_CONFIG["api_key"],
        temperature=0.3,
        max_tokens=500,
    )

    # 6. Ð¢Ð•Ð ÐÐŸÐ•Ð’Ð¢ - Ñ†ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð³ÐµÐ½Ñ‚, Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹ Ð²ÑÐµ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ
    builder.add_agent(
        "general_practitioner",
        display_name="Ð’Ñ€Ð°Ñ‡-Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚",
        persona="Ð’Ñ‹ Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹ Ð²Ñ€Ð°Ñ‡-Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚, ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð¾Ð²",
        description=(
            "Ð’Ñ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¸ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð¾Ñ‚ Ð²ÑÐµÑ… ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð¾Ð². "
            "Ð’Ð°ÑˆÐ° Ð·Ð°Ð´Ð°Ñ‡Ð°:\n"
            "1. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²ÑÐµ Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð¾Ð²\n"
            "2. Ð’Ñ‹ÑÐ²Ð¸Ñ‚ÑŒ ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ð¼Ð¸ ÑÐ¸Ð¼Ð¿Ñ‚Ð¾Ð¼Ð°Ð¼Ð¸\n"
            "3. ÐŸÐ¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð´Ð¸Ð°Ð³Ð½Ð¾Ð· Ð¸Ð»Ð¸ Ð¿Ñ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð´Ð¸Ð°Ð³Ð½Ð¾Ð·\n"
            "4. Ð”Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ñ‹Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð»ÐµÑ‡ÐµÐ½Ð¸ÑŽ Ð¸ Ð´Ð°Ð»ÑŒÐ½ÐµÐ¹ÑˆÐ¸Ð¼ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸ÑÐ¼\n\n"
            "Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð²Ð°Ñˆ Ð¾Ñ‚Ð²ÐµÑ‚:\n"
            "- ÐÐÐÐ›Ð˜Ð—: ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð·Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¹ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð¾Ð²\n"
            "- Ð”Ð˜ÐÐ“ÐÐžÐ—: Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð´Ð¸Ð°Ð³Ð½Ð¾Ð· Ð¸Ð»Ð¸ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ\n"
            "- Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð˜Ð˜: ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ñƒ\n"
        ),
        llm_backbone=DEFAULT_LLM_CONFIG["model_name"],
        base_url=DEFAULT_LLM_CONFIG["base_url"],
        api_key=DEFAULT_LLM_CONFIG["api_key"],
        temperature=0.2,  # Ð‘Ð¾Ð»ÐµÐµ Ð½Ð¸Ð·ÐºÐ°Ñ Ñ‚ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð´Ð»Ñ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð³Ð¾ Ð´Ð¸Ð°Ð³Ð½Ð¾Ð·Ð°
        max_tokens=1500,
    )

    # Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ Ñ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð³Ð¸ÑŽ "Ð·Ð²ÐµÐ·Ð´Ð¾Ñ‡ÐºÐ°": Ð²ÑÐµ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ñ‹ â†’ Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚
    specialists = ["orthopedist", "ophthalmologist", "cardiologist", "neurologist", "dermatologist"]

    for specialist in specialists:
        builder.add_workflow_edge(specialist, "general_practitioner")

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ñƒ (ÑÐ»ÑƒÑ‡Ð°Ð¹ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°)
    builder.add_task(query=PATIENT_CASE, answer="")

    # ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ñƒ ÐºÐ¾ Ð²ÑÐµÐ¼ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð°Ð¼ (Ð¾Ð½Ð¸ Ð²ÑÐµ Ð½Ð°Ñ‡Ð¸Ð½Ð°ÑŽÑ‚ Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑÐ»ÑƒÑ‡Ð°Ñ)
    builder.connect_task_to_agents(agent_ids=specialists)

    return builder.build()


def save_dialogue_history(result, output_path: str = "medical_dialogue_history.json"):
    """Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð² JSON Ñ„Ð°Ð¹Ð»."""
    timestamp = datetime.now().isoformat()

    # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½ÑƒÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ
    dialogue_history: dict = {
        "metadata": {
            "timestamp": timestamp,
            "topology": "star",
            "total_agents": len(result.execution_order),
            "execution_time_seconds": result.total_time,
            "total_tokens": result.total_tokens,
        },
        "patient_case": PATIENT_CASE,
        "specialists_consultation": {},
        "final_diagnosis": {
            "agent": result.final_agent_id,
            "output": {
                "response": result.final_answer,
                "length": len(result.final_answer),
            },
        },
        "execution_flow": {
            "execution_order": result.execution_order,
            "parallel_groups": [],  # Ð‘ÑƒÐ´ÐµÑ‚ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¾ Ð½Ð¸Ð¶Ðµ
        },
        "metrics": {
            "total_time": result.total_time,
            "total_tokens": result.total_tokens,
            "topology_changed_count": result.topology_changed_count,
            "fallback_count": result.fallback_count,
        },
    }

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð¾Ð²
    specialists = ["orthopedist", "ophthalmologist", "cardiologist", "neurologist", "dermatologist"]

    for specialist_id in specialists:
        if specialist_id in result.messages:
            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ€ÑƒÑÑÐºÐ¾Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð°
            display_names = {
                "orthopedist": "ÐžÑ€Ñ‚Ð¾Ð¿ÐµÐ´",
                "ophthalmologist": "ÐžÑ„Ñ‚Ð°Ð»ÑŒÐ¼Ð¾Ð»Ð¾Ð³",
                "cardiologist": "ÐšÐ°Ñ€Ð´Ð¸Ð¾Ð»Ð¾Ð³",
                "neurologist": "ÐÐµÐ²Ñ€Ð¾Ð»Ð¾Ð³",
                "dermatologist": "Ð”ÐµÑ€Ð¼Ð°Ñ‚Ð¾Ð»Ð¾Ð³",
            }

            specialist_data = {
                "display_name": display_names.get(specialist_id, specialist_id),
                "output": {
                    "response": result.messages[specialist_id],
                    "length": len(result.messages[specialist_id]),
                },
                "execution_index": result.execution_order.index(specialist_id)
                if specialist_id in result.execution_order
                else -1,
            }

            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ, ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ Ð±Ñ‹Ð»Ð¸ Ð·Ð°Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹
            if specialist_id in AGENT_IO_LOG:
                io_data = AGENT_IO_LOG[specialist_id]
                specialist_data["input"] = {
                    "prompt": io_data.get("input_prompt", ""),
                    "length": io_data.get("input_length", 0),
                }

            dialogue_history["specialists_consultation"][specialist_id] = specialist_data

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚Ð° (Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð³ÐµÐ½Ñ‚Ð°)
    if result.final_agent_id in AGENT_IO_LOG:
        io_data = AGENT_IO_LOG[result.final_agent_id]
        dialogue_history["final_diagnosis"]["input"] = {
            "prompt": io_data.get("input_prompt", ""),
            "length": io_data.get("input_length", 0),
        }

    # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð³Ñ€ÑƒÐ¿Ð¿Ð°Ñ…, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐµÑ‘
    if result.step_results:
        parallel_info = []
        for agent_id, step_result in result.step_results.items():
            parallel_info.append(
                {
                    "agent": agent_id,
                    "start_time": getattr(step_result, "start_time", None),
                    "end_time": getattr(step_result, "end_time", None),
                }
            )
        dialogue_history["execution_flow"]["parallel_execution_info"] = parallel_info

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð² (ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾)
    if result.agent_states:
        dialogue_history["agent_states"] = result.agent_states

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² Ñ„Ð°Ð¹Ð»
    output_file = Path(__file__).parent / output_path
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(dialogue_history, f, ensure_ascii=False, indent=2)

    return output_file


def print_formatted_results(result):
    """ÐšÑ€Ð°ÑÐ¸Ð²Ð¾ Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð½Ð° ÑÐºÑ€Ð°Ð½."""
    # ÐŸÐ¾Ñ€ÑÐ´Ð¾Ðº Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ

    # Ð—Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð¾Ð²

    specialists_info = [
        ("orthopedist", "ðŸ¦´ ÐžÐ Ð¢ÐžÐŸÐ•Ð”"),
        ("ophthalmologist", "ðŸ‘ï¸ ÐžÐ¤Ð¢ÐÐ›Ð¬ÐœÐžÐ›ÐžÐ“"),
        ("cardiologist", "â¤ï¸ ÐšÐÐ Ð”Ð˜ÐžÐ›ÐžÐ“"),
        ("neurologist", "ðŸ§  ÐÐ•Ð’Ð ÐžÐ›ÐžÐ“"),
        ("dermatologist", "ðŸ§´ Ð”Ð•Ð ÐœÐÐ¢ÐžÐ›ÐžÐ“"),
    ]

    for specialist_id, _specialist_name in specialists_info:
        if specialist_id in result.messages:
            pass

    # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð´Ð¸Ð°Ð³Ð½Ð¾Ð· Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚Ð°

    # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸

    if result.pruned_agents:
        pass


def main():
    """Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ñ Ð¼ÐµÐ´Ð¸Ñ†Ð¸Ð½ÑÐºÐ¸Ð¼Ð¸ Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ð² Ñ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð³Ð¸Ð¸ Ð·Ð²ÐµÐ·Ð´Ð¾Ñ‡ÐºÐ°."""
    # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ ÑÐ»ÑƒÑ‡Ð°Ð¹ Ð¿Ð°Ñ†Ð¸ÐµÐ½Ñ‚Ð°

    # Ð¨Ð°Ð³ 1: Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð³Ñ€Ð°Ñ„Ð°
    start_time = time.time()

    graph = create_medical_graph()

    time.time() - start_time

    # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð³Ð¸ÑŽ
    specialists = ["orthopedist", "ophthalmologist", "cardiologist", "neurologist", "dermatologist"]
    for _specialist in specialists:
        pass

    # Ð¨Ð°Ð³ 2: Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ runner Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»Ð¸Ð·Ð¼Ð°

    # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð»Ð¾Ð³ Ð¿ÐµÑ€ÐµÐ´ Ð·Ð°Ð¿ÑƒÑÐºÐ¾Ð¼
    AGENT_IO_LOG.clear()

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ runner'Ð° Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ
    runner_config = RunnerConfig(
        timeout=120.0,
        adaptive=True,
        enable_parallel=True,  # Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ
        max_parallel_size=5,  # Ð’ÑÐµ 5 ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð¾Ð² Ð¼Ð¾Ð³ÑƒÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾
        broadcast_task_to_all=True,  # Task query Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‘Ñ‚ÑÑ Ð²ÑÐµÐ¼ Ð°Ð³ÐµÐ½Ñ‚Ð°Ð¼
    )

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ factory Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð°/Ð²Ñ‹Ñ…Ð¾Ð´Ð°
    factory = create_logging_caller_factory()

    runner = MACPRunner(
        llm_factory=factory,
        config=runner_config,
    )

    # Ð¨Ð°Ð³ 3: Ð—Ð°Ð¿ÑƒÑÐº ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ð¸

    execution_start = time.time()

    try:
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ñ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð°Ð³ÐµÐ½Ñ‚Ð¾Ð¼ = Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚
        result = runner.run_round(graph, final_agent_id="general_practitioner")

        time.time() - execution_start

        # Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
        print_formatted_results(result)

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð² JSON
        save_dialogue_history(result)

        # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ Ñ‚Ð¾Ð³Ð¾, Ñ‡Ñ‚Ð¾ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð´Ð»Ñ Ñ‚ÐµÑ€Ð°Ð¿ÐµÐ²Ñ‚Ð°
        if "general_practitioner" in AGENT_IO_LOG:
            gp_input = AGENT_IO_LOG["general_practitioner"].get("input_prompt", "")
            if "Messages from other agents:" in gp_input:
                idx = gp_input.find("Messages from other agents:")
                gp_input[idx : idx + 400]
                if len(gp_input[idx:]) > 400:
                    pass
            else:
                pass

        # Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð»Ð¾
        if len(specialists) > 1:
            specialists_in_order = [s for s in result.execution_order if s in specialists]
            if len(specialists_in_order) == len(specialists):
                pass

    except Exception:
        import traceback

        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())
